/* pitch_detection_v2.cpp */

/** Notes
 * 
 *  -- tensorflow's c++ interface seems to be the path of least resistance, since we're loading
 *     protobuf files generated by tensorflow, but it comes at the cost of build complexity
 *  -- https://stackoverflow.com/questions/56837288/tensorflow-lite-c-api-example-for-inference
 *  -- model is currently installed to /usr/local by cmake, but this doesn't seem right. Investigate.
 *  -- SPICE Model: https://www.tensorflow.org/hub/tutorials/spice
 *  -- "The SPICE model needs as input an audio file at a sampling rate of 16kHz 
 *      and with only one channel (mono).
 **/

#include <assert.h>
#include <math.h>
#include <unordered_map>
#include <iostream>

#include "tensorflow/lite/interpreter.h"
#include "tensorflow/lite/kernels/register.h"
#include "tensorflow/lite/model.h"
#include "tensorflow/lite/tools/gen_op_registration.h"
#include "tensorflow/lite/delegates/nnapi/nnapi_delegate.h"
#include "tensorflow/lite/delegates/gpu/delegate.h"
#include "tensorflow/lite/optional_debug_tools.h"

#include "pitch_detection/spice.h"
#include "pitch_detection/exceptions.h"
#include "config.h"
#include "logs.h"

const bool VERBOSE = false;

const float MINIMUM_CONFIDENCE_THRESHOLD = 0.8;

const int SPICE_MODEL_SAMPLE_RATE = 16000;

const int SPICE_MODEL_NUM_CHANNELS = 1;

// the constants below were taken from https://tfhub.dev/google/spice/2

const float PT_OFFSET = 25.58;

const float PT_SLOPE = 63.07;

const float FMIN = 10.0;

const float BINS_PER_OCTAVE = 12.0;

std::unique_ptr<tflite::FlatBufferModel> model { };
std::unique_ptr<tflite::Interpreter> interpreter { };
std::unique_ptr<tflite::InterpreterOptions> options { };

bool pitch_detection::model_is_loaded()
{
    return model.get() != nullptr;
}

void pitch_detection::load_model()
{
    assert(!pitch_detection::model_is_loaded());

    tflite::StderrReporter error_reporter;
    model = tflite::FlatBufferModel::BuildFromFile(config::getPathToSPICEModel().c_str(), &error_reporter);

    tflite::ops::builtin::BuiltinOpResolver resolver;  
    options = std::make_unique<tflite::InterpreterOptions>();
    options->SetEnsureDynamicTensorsAreReleased();

    tflite::InterpreterBuilder builder(*model.get(), resolver, options.get());
    auto interpreterBuildResults = builder(&interpreter);
    if (interpreterBuildResults != kTfLiteOk) { throw pitch_detection::ModelLoadingError(); };

    auto allocationResults = interpreter->AllocateTensors();
    if (allocationResults != kTfLiteOk) { throw pitch_detection::ModelLoadingError(); };

    if (VERBOSE) {
        tflite::PrintInterpreterState(interpreter.get());
    }
}

/**
 * Step 1: apply low pass filter (https://cplusplus.com/forum/general/282026/)
 * Step 2: reduce sample rate
 *    - this reduces buffer size, allowing us to overwrite the signal in-place. 
 *    - Iterate through the buffer while overwriting the initial indecies with the decimated signal. 
 *    - The decimated signal will consists of every Nth sample of the original sample,
 *      where N = Desired Sample Rate / Current Sample Rate
 * Step 3: reduce the buffer to a single channel
 * Step 3: use juce::AudioBuffer::setSize to reduce the buffer to a single channel
 *         as well as safely update the size of the now smaller buffer
 **/
void prepareAudioForModel(juce::AudioBuffer<float>& buffer, int sampleRate)
{
    assert(sampleRate > SPICE_MODEL_SAMPLE_RATE);

    auto applyLowPassFilter = [&buffer] {
        // TODO
    };

    auto downSampleAudio = [&buffer, &sampleRate] {
        int numSamplesAfterDownSampling = SPICE_MODEL_SAMPLE_RATE*buffer.getNumSamples()/sampleRate;
        int channel = 0;
        if (sampleRate > SPICE_MODEL_SAMPLE_RATE) 
        {
            for (int newSignalIndex = 0
               ; newSignalIndex < numSamplesAfterDownSampling
               ; newSignalIndex += 1
            ) {
                int oldSignalIndex = static_cast<int>(
                    std::round(newSignalIndex*sampleRate/SPICE_MODEL_SAMPLE_RATE)
                );
                buffer.setSample(channel, newSignalIndex, buffer.getSample(channel, oldSignalIndex));
            }
        }
        buffer.setSize(1 /* num channels */, numSamplesAfterDownSampling);
    };

    applyLowPassFilter();
    downSampleAudio();
}


float* runModel(juce::AudioBuffer<float>& buffer, int sampleRate)
{
    assert(model);
    assert(interpreter);

    /**
     * NOTE: The spice model expects 10 seconds of audio (16000 samples),
     *       and the samples being used are usually only about 5 seconds in
     *       length. Figure out how to remedy this.
     **/
    float* input = interpreter->typed_input_tensor<float>(0);
    for (int sampleIndex = 0; sampleIndex < buffer.getNumSamples(); sampleIndex++) {
        float normalizedSample = buffer.getSample(0, sampleIndex) / 32768.0;
        input[sampleIndex] = normalizedSample;
    }

    interpreter->Invoke();

    // "A list of values in the interval [0, 1], each of which corresponds to the
    // pitch of the input audio. The size of the array is Ceil(input_size / 512)"
    return interpreter->typed_output_tensor<float>(0);
}

float pitch_detection::getFundementalFrequency(juce::AudioBuffer<float>& buffer, int sampleRate)
{
    if (sampleRate < SPICE_MODEL_SAMPLE_RATE) { // audio quality isn't high enough.
        throw pitch_detection::FrequencyNotDetectedException();
    } else if (!model_is_loaded()) {
        load_model();
    }

    prepareAudioForModel(buffer, sampleRate);
    float* output = runModel(buffer, buffer.getNumSamples());

    float sumOfFrequencies = 0.0;
    for (int sampleIndex = 0; sampleIndex < (buffer.getNumSamples() / 512); sampleIndex++) {
        float cqt_bin = output[sampleIndex] * PT_SLOPE + PT_OFFSET;
        float frequency = FMIN*pow(
            2.0, (1.0 * cqt_bin / BINS_PER_OCTAVE)
        );
        sumOfFrequencies += frequency;
    }

    return sumOfFrequencies / buffer.getNumSamples();
}